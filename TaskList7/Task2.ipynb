{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAkCJip-VI1L"
   },
   "source": [
    "\n",
    "\n",
    "# **Task #2**\n",
    "\n",
    "Basically - scan object and box detected stuff.\n",
    "\n",
    "I'm trying here different object detecting models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4pLloxp9OjU"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **1. Tasklist Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "en0lAStAig07"
   },
   "source": [
    "**Downloading Retinanet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96hgZMqiVRW2"
   },
   "outputs": [],
   "source": [
    "%pip install -q git+https://github.com/fizyr/keras-retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zNV5H6Ex00V"
   },
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "from PIL import Image\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Latest Release model\n",
    "URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = 0\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "setup_gpu(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "068ksXlpx46J"
   },
   "outputs": [],
   "source": [
    "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
    "# model_path = os.path.join('..', 'snapshots', 'resnet50_coco_best_v2.1.0.h5')\n",
    "\n",
    "# load retinanet model\n",
    "model = models.load_model('resnet50_coco_best_v2.1.0.h5', backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "#model = models.convert_model(model)\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjAb6flU1Gal"
   },
   "source": [
    "**Image Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAI9msLS27um"
   },
   "source": [
    "Get Images from Path /my_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsPTcfOP2u8b"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('my_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HdJDNZz3WZ0"
   },
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-mdw0_u7QWm"
   },
   "outputs": [],
   "source": [
    "def exec_image(image_path):\n",
    "  show_inference(detection_model, image_path)\n",
    "  image = read_image_bgr(image_path)\n",
    "\n",
    "  # copy to draw on\n",
    "  draw = image.copy()\n",
    "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # preprocess image for network\n",
    "  image = preprocess_image(image)\n",
    "  image, scale = resize_image(image)\n",
    "\n",
    "  # process image\n",
    "  start = time.time()\n",
    "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "  print(\"processing time: \", time.time() - start)\n",
    "\n",
    "  # correct for image scale\n",
    "  boxes /= scale\n",
    "\n",
    "  # visualize detections\n",
    "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "      # scores are sorted so we can break\n",
    "      if score < 0.5:\n",
    "          break\n",
    "          \n",
    "      color = label_color(label)\n",
    "      \n",
    "      b = box.astype(int)\n",
    "      draw_box(draw, b, color=color)\n",
    "      \n",
    "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "      draw_caption(draw, b, caption)\n",
    "      \n",
    "  plt.figure(figsize=(15, 15))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(draw)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "  exec_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aI8S_Q0x1DkF"
   },
   "source": [
    "**Camera**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3G2R6xcuQpQI"
   },
   "source": [
    "*in case of testing in jupyter notebook on chrome, skip this one block*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnwsaY5t0_jx"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras_retinanet.utils.image import read_image_bgr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grab_camera_snapshot(camera_id=0, fallback_filename='photo.jpg'):\n",
    "    camera = cv2.VideoCapture(camera_id)\n",
    "    print(camera.read())\n",
    "    try:\n",
    "        # bierzemy 15 klatek w praktyce dostajemy lepsze zdjęcia, bo\n",
    "        # kamera lepiej dobierze kontrast i światło w ostatniej klatce\n",
    "        for i in range(15):\n",
    "            snapshot_ok, image = camera.read()\n",
    "        if not snapshot_ok:\n",
    "            print(\"Ups: could not access camera\")\n",
    "            if fallback_filename:\n",
    "                image = read_image_bgr(fallback_filename)\n",
    "    finally:\n",
    "        camera.release()\n",
    "\n",
    "    exec_image('photo.jpg')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yvna-5aKRhjv"
   },
   "outputs": [],
   "source": [
    "grab_camera_snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsPGRqrpQRMP"
   },
   "source": [
    "**Launching Camera in jupyter notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zpT8_RMQHlf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TV294XomQJyi"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  # Show the image which was just taken.\n",
    "  display(Image(filename))\n",
    "\n",
    "  # Scan the Image\n",
    "  exec_image('photo.jpg')\n",
    "except Exception as err:\n",
    "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
    "  # grant the page permission to access it.\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w39IP9aFTUv6"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "exec_image('photo.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7vsr-BT0zLv"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **2. Tensorflow Models Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tr1Fz9KNgaBR"
   },
   "source": [
    "**Getting Tensorflow Models and Coco Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKK_tYp7gQ0I"
   },
   "outputs": [],
   "source": [
    "!pip install -U --pre tensorflow==\"2.*\"\n",
    "!pip install tf_slim\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "001PAHMFght4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1zjVwcog5oD"
   },
   "source": [
    "**Compiling Protobufs and Installing Object Detection Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rf85Hf1gz17"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMiJ8zuQhCCP"
   },
   "source": [
    "**Preparing libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L4kuTYEhhBfJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7siIqqFmhfKG"
   },
   "source": [
    "**Preping Model Loader** *https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s05e0iYFhjJW"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mq1h93fHhxab"
   },
   "source": [
    "**Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Orn28pThzC4"
   },
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2U1KSE6iCRC"
   },
   "source": [
    "**Detection** *Detection Model takes as input batch of 3-color images, while outputing among others amount of detections, scores and boxes*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4lR7VY9iDpM"
   },
   "outputs": [],
   "source": [
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQ6BFlCdi1rg"
   },
   "source": [
    "**Function to call the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpUyOsioihEm"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "    \n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], \n",
    "              output_dict['detection_boxes'],\n",
    "              image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5 tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "  return output_dict\n",
    "\n",
    "def show_inference(model, image_path):\n",
    "  image_np = np.array(Image.open(image_path))\n",
    "  output_dict = run_inference_for_single_image(model, image_np)\n",
    "\n",
    "  # Visualization of the results of a detection.\n",
    "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "\n",
    "  display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S1ZGbHBDizDl"
   },
   "source": [
    "**Execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "  show_inference(detection_model, image_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TaskList #7 Task #2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
